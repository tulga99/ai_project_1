{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd9d86ef-0a4f-419d-a3ca-e95c563f5b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d2f359-0eb9-4925-ab78-75c6a39c33c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return self.sigmoid(A)\n",
    "    def backward(self, dZ):\n",
    "        _sig = self.sigmoid(self.A)\n",
    "        return dZ * (1 - _sig)*_sig\n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "class Tanh:\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.tanh(A)\n",
    "    def backward(self, dZ):\n",
    "        return dZ * (1 - (np.tanh(self.A))**2)\n",
    "\n",
    "class Softmax:\n",
    "    def forward(self, X):\n",
    "        self.Z = np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1,1)\n",
    "        return self.Z\n",
    "    def backward(self, Y):\n",
    "        self.loss = self.loss_func(Y)\n",
    "        return self.Z - Y\n",
    "    def loss_func(self, Y, Z=None):\n",
    "        if Z is None:\n",
    "            Z = self.Z\n",
    "        return (-1)*np.average(np.sum(Y*np.log(Z), axis=1))\n",
    "\n",
    "class ReLU:\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.clip(A, 0, None)\n",
    "    def backward(self, dZ):\n",
    "        return dZ * np.clip(np.sign(self.A), 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5c5ef9-c543-4767-8106-236481321c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        A = X@self.W + self.B\n",
    "        return A\n",
    "    def backward(self, dA):\n",
    "        dZ = dA@self.W.T\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        self.dW = self.X.T@dA\n",
    "        self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ada3ad-7762-4829-8f56-368321401402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = math.sqrt(1 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B\n",
    "    \n",
    "class HeInitializer():\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = math.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B\n",
    "        \n",
    "class SimpleInitializer:\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, *shape):\n",
    "        W = self.sigma * np.random.randn(*shape)\n",
    "        return W\n",
    "    def B(self, *shape):\n",
    "        B = self.sigma * np.random.randn(*shape)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4879b1de-7993-4a45-9294-e3775af17b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.B -= self.lr * layer.dB\n",
    "        return\n",
    "\n",
    "class AdaGrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.HW = 1\n",
    "        self.HB = 1\n",
    "    def update(self, layer):\n",
    "        self.HW += layer.dW**2\n",
    "        self.HB += layer.dB**2\n",
    "        layer.W -= self.lr * np.sqrt(1/self.HW) * layer.dW\n",
    "        layer.B -= self.lr * np.sqrt(1/self.HB) * layer.dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06431edf-beb9-47eb-b827-ca852915d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1] \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ec3cf-6c91-4783-af9c-8e7075a864e8",
   "metadata": {},
   "source": [
    "# [Problem 1] Creating a one-dimensional convolutional layer class with a limited number of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13efc3c3-775e-44d5-b0d9-329212d7a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d():\n",
    "    def forward(self, x, w, b):\n",
    "        a = []\n",
    "        for i in range(len(w) - 1):\n",
    "            a.append((x[i:i+len(w)] @ w) + b[0])\n",
    "        return np.array(a)\n",
    "    def backward(self, x, w, da):\n",
    "        db = np.sum(da)\n",
    "        dw = []\n",
    "        for i in range(len(w)):\n",
    "            dw.append(da @ x[i:i+len(da)])\n",
    "        dw = np.array(dw)\n",
    "        dx = []\n",
    "        new_w = np.insert(w[::-1], 0, 0)\n",
    "        new_w = np.append(new_w, 0)\n",
    "        for i in range(len(new_w)-1):\n",
    "            dx.append(new_w[i:i+len(da)] @ da)\n",
    "        dx = np.array(dx[::-1])\n",
    "        return db, dw, dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78aee36-176f-4265-ba17-012bd1e9dbcb",
   "metadata": {},
   "source": [
    "# [Problem 2] Calculation of output size after one-dimensional convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1dbd1f-0471-4bea-8916-d313cf11b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 2\n"
     ]
    }
   ],
   "source": [
    "def output_size_calculation( n_in, filter_size, padding=0, stride=1):\n",
    "        n_out = int((n_in + 2*padding - filter_size) / stride + 1)   \n",
    "        return n_out\n",
    "\n",
    "a = output_size_calculation(4,3,0,1)\n",
    "print(\"result:\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279ca17a-7316-4be2-8218-af4e55430359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Problem 3] One-dimensional convolutional layer experiment with small arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06673f43-7171-4a7b-ab29-9540ad3d536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbb91eb1-e921-4f3e-a3a0-ee837b63edaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 50])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_conv_1d = SimpleConv1d()\n",
    "simple_conv_1d.forward(x, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f97b64d-aea9-46cf-98e5-13d523d6a944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, array([ 50,  80, 110]), array([ 30, 110, 170, 140]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([35, 50])\n",
    "a_actual = np.array([45, 70])\n",
    "da = np.array([10, 20])\n",
    "db, dw, dx = simple_conv_1d.backward(x, w, da)\n",
    "db, dw, dx\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441cbcfb-346f-4739-9f91-43d87392f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "w = np.array([3, 5, 7])\n",
    "\n",
    "a = np.empty((2, 3))\n",
    "\n",
    "indexes0 = np.array([0, 1, 2]).astype(np.int32)\n",
    "indexes1 = np.array([1, 2, 3]).astype(np.int32)\n",
    "\n",
    "a[0] = x[indexes0]*w # x[indexes0]は([1, 2, 3])である\n",
    "a[1] = x[indexes1]*w # x[indexes1]は([2, 3, 4])である\n",
    "\n",
    "a = a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbd8862a-af76-4638-8baf-c2cd4550e311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "indexes = np.array([[0, 1, 2], [1, 2, 3]]).astype(np.int32)\n",
    "\n",
    "print(x[indexes]) # ([[1, 2, 3], [2, 3, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dcd673-ad3b-4961-8fe4-c1ae68579a2b",
   "metadata": {},
   "source": [
    "# [Problem 4] Creating a one-dimensional convolutional layer class that does not limit the number of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcd2c9fd-57d7-450c-84c5-1376d150bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47cf441e-be83-4110-b750-aca3fd77cd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print forward prop: [[16. 22.]\n",
      " [17. 23.]\n",
      " [18. 24.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros([3, output_size_calculation(4,3,0,1)])\n",
    "\n",
    "for och in range(w.shape[0]):\n",
    "    for ch in range(w.shape[1]):\n",
    "        for m in range(a.shape[1]):\n",
    "            a[och,m] += np.sum(x[ch, m:m+w.shape[2]]* w[och,ch,:])\n",
    "\n",
    "a += b[:,None]\n",
    "print(\"print forward prop:\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2b5bd81-4511-4c04-97cb-9928452b881b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res: 2\n"
     ]
    }
   ],
   "source": [
    "class Conv1d:\n",
    "    def __init__(self, b_size, initializer, optimizer, n_in_channels=1, n_out_channels=1, pa=0):\n",
    "        self.b_size = b_size\n",
    "        self.optimizer = AdaGrad\n",
    "        self.Initializer = XavierInitializer\n",
    "        self.pa = pa\n",
    "        self.W = initializer.W(n_out_channels, n_in_channels, b_size)\n",
    "        self.B = initializer.B(n_out_channels)\n",
    "        self.n_in_channels = n_in_channels\n",
    "        self.n_out_channels = n_out_channels\n",
    "        self.n_out = None\n",
    "    def forward(self, X):\n",
    "        self.n_samples = X.shape[0]\n",
    "        self.n_in = X.shape[-1]\n",
    "        self.n_out = output_size_calculation(self.n_in, self.b_size, self.pa, self.stride)\n",
    "        X = X.reshape(self.n_samples, self.n_in_channels, self.n_in)\n",
    "        self.X = np.pad(X, ((0,0), (0,0), ((self.b_size-1), 0)))\n",
    "        self.X1 = np.zeros((self.n_samples, self.n_in_channels, self.b_size, self.n_in+(self.b_size-1)))\n",
    "        for i in range(self.b_size):\n",
    "            self.X1[:, :, i] = np.roll(self.X, -i, axis=-1)\n",
    "        A = np.sum(self.X1[:, np.newaxis, :, :, self.b_size-1-self.pa:self.n_in+self.pa:self.stride]*self.W[:, :, :, np.newaxis], axis=(2, 3)) + self.B.reshape(-1,1)\n",
    "        return A\n",
    "    def backward(self, dA):\n",
    "        self.dW = np.sum(dA[:, :, np.newaxis, np.newaxis]*self.X1[:, np.newaxis, :, :, self.b_size-1-self.pa:self.n_in+self.pa:self.stride], axis=(0, -1))\n",
    "        self.dB = np.sum(dA, axis=(0, -1))\n",
    "        self.dA = np.pad(dA, ((0,0), (0,0), (0, (self.b_size-1))))\n",
    "        self.dA1 = np.zeros((self.n_samples, self.n_out_channels, self.b_size, self.dA.shape[-1]))\n",
    "        for i in range(self.b_size):\n",
    "            self.dA1[:, :, i] = np.roll(self.dA, i, axis=-1)\n",
    "        dX = np.sum(self.W[:, :, :, np.newaxis]*self.dA1[:, :, np.newaxis], axis=(1,3))\n",
    "        self.optimizer.update(self)\n",
    "        return dX\n",
    "    def output_size_calculation( n_in, filter_size, padding=0, stride=1):\n",
    "            n_out = int((n_in + 2*padding - filter_size) / stride + 1)   \n",
    "            return n_out\n",
    "\n",
    "    a = output_size_calculation(4,3,0,1)\n",
    "    print(\"res:\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b7639-9eae-456a-b4c7-edce93fa13f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
